"""
FastAPI AI Service - Extended APIs
C√°c API m·ªü r·ªông cho AI: Generate Quiz, Summarize, Explain, Ingest
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, ConfigDict
from typing import List, Optional
import google.generativeai as genai
import os
from dotenv import load_dotenv
import requests
import json
import re

# Load environment variables
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY or GEMINI_API_KEY == "your_gemini_api_key_here":
    raise ValueError("‚ö†Ô∏è  GEMINI_API_KEY kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y trong file .env")

genai.configure(api_key=GEMINI_API_KEY)

# Initialize FastAPI app
app = FastAPI(
    title="AI Service Extended APIs",
    description="API m·ªü r·ªông cho AI: Quiz Generation, Summarization, Explain, Ingest",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# PYDANTIC MODELS
# ============================================================================

class GenerateQuizRequest(BaseModel):
    content: str
    num_questions: int = 10
    difficulty: str = "medium"  # easy, medium, hard
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "content": "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh b·∫≠c cao...",
                "num_questions": 10,
                "difficulty": "medium"
            }
        }
    )

class QuizQuestion(BaseModel):
    question: str
    a: str
    b: str
    c: str
    d: str
    correct: str  # 'A', 'B', 'C', 'D'

class GenerateQuizResponse(BaseModel):
    questions: List[QuizQuestion]

class SummarizeRequest(BaseModel):
    content: str
    max_length: Optional[int] = 200
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "content": "VƒÉn b·∫£n d√†i c·∫ßn t√≥m t·∫Øt...",
                "max_length": 200
            }
        }
    )

class SummarizeResponse(BaseModel):
    summary: str
    original_length: int
    summary_length: int

class ExplainRequest(BaseModel):
    question: str
    context: Optional[str] = None
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "question": "ƒê·ªãnh l√Ω Pythagoras l√† g√¨?",
                "context": "To√°n h·ªçc l·ªõp 9"
            }
        }
    )

class ExplainResponse(BaseModel):
    explanation: str
    examples: Optional[List[str]] = None

class IngestRequest(BaseModel):
    file_url: str
    title: Optional[str] = None
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "file_url": "https://example.com/document.pdf",
                "title": "T√†i li·ªáu h·ªçc t·∫≠p"
            }
        }
    )

class IngestResponse(BaseModel):
    status: str
    message: str
    documents_added: int

# ============================================================================
# API ENDPOINTS
# ============================================================================

@app.get("/", tags=["Health"])
async def root():
    """Health check endpoint"""
    return {
        "status": "running",
        "service": "AI Service Extended APIs",
        "version": "1.0.0"
    }

@app.post("/api/ai/generate-quiz", response_model=GenerateQuizResponse, tags=["AI - Quiz"])
async def generate_quiz(request: GenerateQuizRequest):
    """
    T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám t·ª± ƒë·ªông t·ª´ n·ªôi dung b√†i h·ªçc
    
    - **content**: N·ªôi dung b√†i h·ªçc
    - **num_questions**: S·ªë c√¢u h·ªèi c·∫ßn t·∫°o (1-50)
    - **difficulty**: ƒê·ªô kh√≥ (easy, medium, hard)
    """
    try:
        if request.num_questions < 1 or request.num_questions > 50:
            raise HTTPException(status_code=400, detail="S·ªë c√¢u h·ªèi ph·∫£i t·ª´ 1-50")
        
        difficulty_map = {
            "easy": "d·ªÖ, c∆° b·∫£n",
            "medium": "trung b√¨nh",
            "hard": "kh√≥, n√¢ng cao"
        }
        
        difficulty_desc = difficulty_map.get(request.difficulty.lower(), "trung b√¨nh")
        
        prompt = f"""D·ª±a tr√™n n·ªôi dung sau, h√£y t·∫°o {request.num_questions} c√¢u h·ªèi tr·∫Øc nghi·ªám v·ªõi ƒë·ªô kh√≥ {difficulty_desc}.

N·ªôi dung:
{request.content}

Y√™u c·∫ßu:
- T·∫°o ƒë√∫ng {request.num_questions} c√¢u h·ªèi
- M·ªói c√¢u c√≥ 4 ƒë√°p √°n A, B, C, D
- Ch·ªâ 1 ƒë√°p √°n ƒë√∫ng
- C√¢u h·ªèi ph·∫£i li√™n quan tr·ª±c ti·∫øp ƒë·∫øn n·ªôi dung
- Tr·∫£ v·ªÅ JSON array v·ªõi format:

[
  {{
    "question": "C√¢u h·ªèi?",
    "a": "ƒê√°p √°n A",
    "b": "ƒê√°p √°n B",
    "c": "ƒê√°p √°n C",
    "d": "ƒê√°p √°n D",
    "correct": "A"
  }}
]

CH·ªà TR·∫¢ V·ªÄ JSON, KH√îNG TH√äM TEXT KH√ÅC."""

        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        
        # Parse JSON t·ª´ response
        json_text = response.text.strip()
        
        # T√¨m JSON array trong response
        json_match = re.search(r'\[.*\]', json_text, re.DOTALL)
        if not json_match:
            raise HTTPException(status_code=500, detail="Kh√¥ng th·ªÉ parse JSON t·ª´ AI response")
        
        questions_data = json.loads(json_match.group())
        
        questions = []
        for q in questions_data:
            questions.append(QuizQuestion(
                question=q['question'],
                a=q['a'],
                b=q['b'],
                c=q['c'],
                d=q['d'],
                correct=q['correct'].upper()
            ))
        
        return GenerateQuizResponse(questions=questions)
    
    except json.JSONDecodeError as e:
        raise HTTPException(status_code=500, detail=f"L·ªói parse JSON: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")

@app.post("/api/ai/summarize", response_model=SummarizeResponse, tags=["AI - Summarization"])
async def summarize(request: SummarizeRequest):
    """
    T√≥m t·∫Øt vƒÉn b·∫£n
    
    - **content**: N·ªôi dung c·∫ßn t√≥m t·∫Øt
    - **max_length**: ƒê·ªô d√†i t·ªëi ƒëa c·ªßa b·∫£n t√≥m t·∫Øt (s·ªë t·ª´)
    """
    try:
        prompt = f"""H√£y t√≥m t·∫Øt vƒÉn b·∫£n sau trong kho·∫£ng {request.max_length} t·ª´:

{request.content}

Y√™u c·∫ßu:
- Gi·ªØ l·∫°i √Ω ch√≠nh
- Ng·∫Øn g·ªçn, s√∫c t√≠ch
- D·ªÖ hi·ªÉu
- Kh√¥ng th√™m th√¥ng tin ngo√†i vƒÉn b·∫£n g·ªëc"""

        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        
        summary = response.text.strip()
        
        return SummarizeResponse(
            summary=summary,
            original_length=len(request.content.split()),
            summary_length=len(summary.split())
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")

@app.post("/api/ai/explain", response_model=ExplainResponse, tags=["AI - Explain"])
async def explain(request: ExplainRequest):
    """
    Gi·∫£i th√≠ch nh∆∞ m·ªôt gi√°o vi√™n
    
    - **question**: C√¢u h·ªèi c·∫ßn gi·∫£i th√≠ch
    - **context**: Ng·ªØ c·∫£nh (t√πy ch·ªçn)
    """
    try:
        context_text = f"\nNg·ªØ c·∫£nh: {request.context}" if request.context else ""
        
        prompt = f"""B·∫°n l√† m·ªôt gi√°o vi√™n gi·ªèi. H√£y gi·∫£i th√≠ch c√¢u h·ªèi sau m·ªôt c√°ch d·ªÖ hi·ªÉu, chi ti·∫øt:{context_text}

C√¢u h·ªèi: {request.question}

Y√™u c·∫ßu:
- Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu
- S·ª≠ d·ª•ng v√≠ d·ª• c·ª• th·ªÉ
- Chia nh·ªè th√†nh c√°c b∆∞·ªõc n·∫øu c·∫ßn
- Gi·ªçng ƒëi·ªáu th√¢n thi·ªán, khuy·∫øn kh√≠ch h·ªçc t·∫≠p

Sau ph·∫ßn gi·∫£i th√≠ch, h√£y ƒë∆∞a ra 2-3 v√≠ d·ª• minh h·ªça."""

        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        
        explanation = response.text.strip()
        
        # T√°ch examples n·∫øu c√≥
        examples = []
        if "V√≠ d·ª•" in explanation or "Example" in explanation:
            parts = re.split(r'V√≠ d·ª• \d+:|Example \d+:', explanation)
            if len(parts) > 1:
                examples = [ex.strip() for ex in parts[1:]]
        
        return ExplainResponse(
            explanation=explanation,
            examples=examples if examples else None
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")

@app.post("/api/ai/ingest", response_model=IngestResponse, tags=["AI - RAG Ingest"])
async def ingest_document(request: IngestRequest):
    """
    Ingest t√†i li·ªáu v√†o RAG Vector Database
    
    - **file_url**: URL c·ªßa file c·∫ßn ingest
    - **title**: Ti√™u ƒë·ªÅ t√†i li·ªáu (t√πy ch·ªçn)
    
    H·ªó tr·ª£: PDF, TXT, HTML, DOC
    """
    try:
        # 1. Download v√† extract text t·ª´ file
        text_content = await extract_text_from_url(request.file_url)
        
        if not text_content:
            raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ extract text t·ª´ file")
        
        # 2. Chia nh·ªè text th√†nh chunks
        chunks = split_text_into_chunks(text_content, chunk_size=500)
        
        # 3. G·ªçi RAG endpoint ƒë·ªÉ th√™m v√†o vector DB
        rag_url = "http://localhost:8000/api/documents/add"
        
        metadatas = [{
            "source": request.file_url,
            "title": request.title or "Untitled",
            "type": "document"
        } for _ in chunks]
        
        rag_request = {
            "documents": chunks,
            "metadatas": metadatas
        }
        
        response = requests.post(rag_url, json=rag_request)
        
        if response.status_code != 200:
            raise HTTPException(status_code=500, detail="L·ªói khi th√™m v√†o RAG database")
        
        return IngestResponse(
            status="success",
            message=f"ƒê√£ ingest {len(chunks)} chunks v√†o RAG database",
            documents_added=len(chunks)
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói: {str(e)}")

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

async def extract_text_from_url(url: str) -> str:
    """Extract text t·ª´ URL (simplified version)"""
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # Simplified: ch·ªâ x·ª≠ l√Ω text/plain
        if 'text' in response.headers.get('Content-Type', ''):
            return response.text
        
        # V·ªõi PDF, DOC c·∫ßn th√™m libraries nh∆∞ PyPDF2, python-docx
        # ƒê√¢y l√† placeholder
        return response.text[:10000]  # Gi·ªõi h·∫°n 10k chars
    
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"L·ªói khi download file: {str(e)}")

def split_text_into_chunks(text: str, chunk_size: int = 500) -> List[str]:
    """Chia text th√†nh c√°c chunks nh·ªè"""
    words = text.split()
    chunks = []
    
    for i in range(0, len(words), chunk_size):
        chunk = ' '.join(words[i:i + chunk_size])
        chunks.append(chunk)
    
    return chunks

# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("AI_SERVICE_PORT", 8001))
    print("=" * 60)
    print("üöÄ Starting AI Service Extended APIs")
    print("=" * 60)
    print(f"üìç Server: http://localhost:{port}")
    print(f"üìö Swagger UI: http://localhost:{port}/docs")
    print("=" * 60)
    uvicorn.run("ai_service:app", host="0.0.0.0", port=port, reload=True)
